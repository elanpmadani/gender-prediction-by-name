{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method untuk One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(i):\n",
    "    temp = np.zeros(28)\n",
    "    temp[i] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15103"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datanama.csv')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Nama\"] = data.Nama.str.lower() \n",
    "data[\"Nama\"] = data.Nama.apply(lambda x: re.sub(r\"[^a-z]\",\" \",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "temp = np.random.rand(len(data)) < 0.8\n",
    "train = data[temp]\n",
    "test = data[~temp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(' '.join([str(i) for i in data[\"Nama\"]]))\n",
    "vocabulary.add(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 32\n",
    "len_vocab = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_index = dict((c,i) for i,c in enumerate(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proses data menjadi one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "ytrain = []\n",
    "namanya= [str(i)[0:maxlen] for i in train.Nama]\n",
    "for i in namanya:\n",
    "    temp =[one_hot_encode(set_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        temp.append(one_hot_encode(set_index[\"END\"]))\n",
    "    xtrain.append(temp)\n",
    "for j in train.gender:\n",
    "    if j == \"m\":\n",
    "        ytrain.append([1,0])\n",
    "    else:\n",
    "        ytrain.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11991, 32, 28)\n",
      "(11991, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(xtrain).shape)\n",
    "print(np.asarray(ytrain).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membuat model neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen,len_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = []\n",
    "ytest = []\n",
    "namanya= [str(i)[0:maxlen] for i in test.Nama]\n",
    "for i in namanya:\n",
    "    temp =[one_hot_encode(set_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        temp.append(one_hot_encode(set_index[\"END\"]))\n",
    "    xtest.append(temp)\n",
    "for j in test.gender:\n",
    "    if j == \"m\":\n",
    "        ytest.append([1,0])\n",
    "    else:\n",
    "        ytest.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2927, 32, 28)\n",
      "(2927, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(xtest).shape)\n",
    "print(np.asarray(ytest).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\elmayo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11991 samples, validate on 2927 samples\n",
      "Epoch 1/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.6966 - acc: 0.5046 - val_loss: 0.6851 - val_acc: 0.5118\n",
      "Epoch 2/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.6056 - acc: 0.6833 - val_loss: 0.5916 - val_acc: 0.7229\n",
      "Epoch 3/50\n",
      "11991/11991 [==============================] - 99s 8ms/step - loss: 0.5298 - acc: 0.7491 - val_loss: 0.5164 - val_acc: 0.7591\n",
      "Epoch 4/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.4924 - acc: 0.7650 - val_loss: 0.4962 - val_acc: 0.7602\n",
      "Epoch 5/50\n",
      "11991/11991 [==============================] - 99s 8ms/step - loss: 0.4800 - acc: 0.7683 - val_loss: 0.4691 - val_acc: 0.7865\n",
      "Epoch 6/50\n",
      "11991/11991 [==============================] - 100s 8ms/step - loss: 0.4632 - acc: 0.7808 - val_loss: 0.4639 - val_acc: 0.7868\n",
      "Epoch 7/50\n",
      "11991/11991 [==============================] - 100s 8ms/step - loss: 0.4573 - acc: 0.7845 - val_loss: 0.4706 - val_acc: 0.7834\n",
      "Epoch 8/50\n",
      "11991/11991 [==============================] - 100s 8ms/step - loss: 0.4455 - acc: 0.7932 - val_loss: 0.4382 - val_acc: 0.8036\n",
      "Epoch 9/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.4309 - acc: 0.8004 - val_loss: 0.4223 - val_acc: 0.8094\n",
      "Epoch 10/50\n",
      "11991/11991 [==============================] - 102s 9ms/step - loss: 0.4135 - acc: 0.8099 - val_loss: 0.4032 - val_acc: 0.8247\n",
      "Epoch 11/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.4011 - acc: 0.8184 - val_loss: 0.3950 - val_acc: 0.8261\n",
      "Epoch 12/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.3781 - acc: 0.8264 - val_loss: 0.3820 - val_acc: 0.8370\n",
      "Epoch 13/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.3644 - acc: 0.8393 - val_loss: 0.3476 - val_acc: 0.8487\n",
      "Epoch 14/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.3448 - acc: 0.8489 - val_loss: 0.3430 - val_acc: 0.8541\n",
      "Epoch 15/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.3292 - acc: 0.8550 - val_loss: 0.3310 - val_acc: 0.8531\n",
      "Epoch 16/50\n",
      "11991/11991 [==============================] - 102s 8ms/step - loss: 0.3126 - acc: 0.8706 - val_loss: 0.3148 - val_acc: 0.8702\n",
      "Epoch 17/50\n",
      "11991/11991 [==============================] - 96s 8ms/step - loss: 0.3044 - acc: 0.8737 - val_loss: 0.3052 - val_acc: 0.8739\n",
      "Epoch 18/50\n",
      "11991/11991 [==============================] - 95s 8ms/step - loss: 0.2917 - acc: 0.8780 - val_loss: 0.3114 - val_acc: 0.8736\n",
      "Epoch 19/50\n",
      "11991/11991 [==============================] - 96s 8ms/step - loss: 0.2795 - acc: 0.8862 - val_loss: 0.3063 - val_acc: 0.8691\n",
      "Epoch 20/50\n",
      "11991/11991 [==============================] - 96s 8ms/step - loss: 0.2617 - acc: 0.8941 - val_loss: 0.2609 - val_acc: 0.8937\n",
      "Epoch 21/50\n",
      "11991/11991 [==============================] - 99s 8ms/step - loss: 0.2467 - acc: 0.8999 - val_loss: 0.2702 - val_acc: 0.8931\n",
      "Epoch 22/50\n",
      "11991/11991 [==============================] - 102s 8ms/step - loss: 0.2380 - acc: 0.9057 - val_loss: 0.2587 - val_acc: 0.8955\n",
      "Epoch 23/50\n",
      "11991/11991 [==============================] - 102s 9ms/step - loss: 0.2390 - acc: 0.9038 - val_loss: 0.2617 - val_acc: 0.9030\n",
      "Epoch 24/50\n",
      "11991/11991 [==============================] - 103s 9ms/step - loss: 0.2260 - acc: 0.9088 - val_loss: 0.2510 - val_acc: 0.9019\n",
      "Epoch 25/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.2147 - acc: 0.9160 - val_loss: 0.2447 - val_acc: 0.8982\n",
      "Epoch 26/50\n",
      "11991/11991 [==============================] - 102s 8ms/step - loss: 0.2136 - acc: 0.9167 - val_loss: 0.2351 - val_acc: 0.9019\n",
      "Epoch 27/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.1993 - acc: 0.9222 - val_loss: 0.2390 - val_acc: 0.9050\n",
      "Epoch 28/50\n",
      "11991/11991 [==============================] - 101s 8ms/step - loss: 0.1996 - acc: 0.9212 - val_loss: 0.2699 - val_acc: 0.8972\n",
      "Epoch 29/50\n",
      "11991/11991 [==============================] - 111s 9ms/step - loss: 0.2054 - acc: 0.9197 - val_loss: 0.2598 - val_acc: 0.9006\n",
      "Epoch 30/50\n",
      "11991/11991 [==============================] - 107s 9ms/step - loss: 0.1923 - acc: 0.9239 - val_loss: 0.2338 - val_acc: 0.9088\n",
      "Epoch 31/50\n",
      "11991/11991 [==============================] - 109s 9ms/step - loss: 0.1843 - acc: 0.9301 - val_loss: 0.2299 - val_acc: 0.9098\n",
      "Epoch 32/50\n",
      "11991/11991 [==============================] - 109s 9ms/step - loss: 0.1806 - acc: 0.9304 - val_loss: 0.2393 - val_acc: 0.9084\n",
      "Epoch 33/50\n",
      "11991/11991 [==============================] - 108s 9ms/step - loss: 0.1809 - acc: 0.9285 - val_loss: 0.2205 - val_acc: 0.9119\n",
      "Epoch 34/50\n",
      "11991/11991 [==============================] - 109s 9ms/step - loss: 0.1712 - acc: 0.9324 - val_loss: 0.2230 - val_acc: 0.9166\n",
      "Epoch 35/50\n",
      "11991/11991 [==============================] - 110s 9ms/step - loss: 0.1571 - acc: 0.9401 - val_loss: 0.2223 - val_acc: 0.9142\n",
      "Epoch 36/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1638 - acc: 0.9385 - val_loss: 0.2307 - val_acc: 0.9187\n",
      "Epoch 37/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1661 - acc: 0.9365 - val_loss: 0.2261 - val_acc: 0.9163\n",
      "Epoch 38/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1592 - acc: 0.9403 - val_loss: 0.2204 - val_acc: 0.9160\n",
      "Epoch 39/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1529 - acc: 0.9404 - val_loss: 0.2225 - val_acc: 0.9170\n",
      "Epoch 40/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1480 - acc: 0.9449 - val_loss: 0.2390 - val_acc: 0.9142\n",
      "Epoch 41/50\n",
      "11991/11991 [==============================] - 96s 8ms/step - loss: 0.1381 - acc: 0.9495 - val_loss: 0.2307 - val_acc: 0.9177\n",
      "Epoch 42/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1296 - acc: 0.9527 - val_loss: 0.2310 - val_acc: 0.9132\n",
      "Epoch 43/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1359 - acc: 0.9502 - val_loss: 0.2308 - val_acc: 0.9095\n",
      "Epoch 44/50\n",
      "11991/11991 [==============================] - 97s 8ms/step - loss: 0.1329 - acc: 0.9483 - val_loss: 0.2445 - val_acc: 0.9153\n",
      "Epoch 45/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1267 - acc: 0.9545 - val_loss: 0.2472 - val_acc: 0.9211\n",
      "Epoch 46/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1276 - acc: 0.9527 - val_loss: 0.2202 - val_acc: 0.9177\n",
      "Epoch 47/50\n",
      "11991/11991 [==============================] - 99s 8ms/step - loss: 0.1249 - acc: 0.9556 - val_loss: 0.2457 - val_acc: 0.9095\n",
      "Epoch 48/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1174 - acc: 0.9578 - val_loss: 0.2436 - val_acc: 0.9190\n",
      "Epoch 49/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1126 - acc: 0.9578 - val_loss: 0.2605 - val_acc: 0.9129\n",
      "Epoch 50/50\n",
      "11991/11991 [==============================] - 98s 8ms/step - loss: 0.1102 - acc: 0.9583 - val_loss: 0.2434 - val_acc: 0.9173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20de676b710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(np.array(xtrain), np.array(ytrain),batch_size=batch_size,epochs=50,validation_data= (np.array(xtest),np.array(ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927/2927 [==============================] - 8s 3ms/step\n",
      "score = 0.24336701552127465\n",
      "acc =  0.9173214896408657\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(np.asarray(xtest),np.asarray(ytest))\n",
    "print('score =',score)\n",
    "print('acc = ',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "testing = ['wahyu nugroho','shinta kurniawati','yoshi setiawan']\n",
    "for i in testing:\n",
    "    temp =[one_hot_encode(set_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        temp.append(one_hot_encode(set_index[\"END\"]))\n",
    "    x.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9814963e-01, 1.8504190e-03],\n",
       "       [2.9698084e-04, 9.9970299e-01],\n",
       "       [9.6287429e-01, 3.7125748e-02]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.asarray(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GenderClassificationLSTMModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('gender_model',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.predict(np.asarray(xtest))\n",
    "prob_m = [i[0] for i in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wew = pd.DataFrame(prob_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wew['name'] = test.Nama.reset_index()['Nama']\n",
    "wew['gender']=test.gender.reset_index()['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
